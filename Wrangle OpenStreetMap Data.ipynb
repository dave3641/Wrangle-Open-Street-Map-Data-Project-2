{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Wrangle OpenStreetMap Data With SQL\n",
    "\n",
    "## Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#intro\">Introduction</a></li>\n",
    "<li><a href=\"#area\">Map Area</a></li>\n",
    "<li><a href=\"#clean\">Cleaning The Data</a></li>\n",
    "<li><a href=\"#csv\">Create CSV Files</a></li>\n",
    "<li><a href=\"#sqldb\">Create The SQL Database</a></li>\n",
    "<li><a href=\"#queries\">SQL Queries</a></li>\n",
    "<li><a href=\"#queries2\">Further SQL Queries</a></li>\n",
    "<li><a href=\"#conclusions\">Conclusions</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "First of all I downloaded small area of data around where I live from -\n",
    "\n",
    "https://www.openstreetmap.org/export#map=16/53.2659/-2.8812\n",
    "\n",
    "I used the websites export function and downloaded a small map file.\n",
    "\n",
    "**SmallMap.osm -> 28.6MB**\n",
    "\n",
    "I opened the fie in Notepad++ (https://notepad-plus-plus.org/) and searched for my postcode, which was not listed, but my street name was.\n",
    "Further searching in the data I found that the postcodes were only listed for business addresses and postboxes, and not for every street.\n",
    "\n",
    "This is probably because the full UK postcode database is owned by Royal Mail, who charge for use of the full database, see -https://www.bbc.co.uk/news/business-26605375"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='area'></a>\n",
    "## Map Area\n",
    "I then expanded to a larger area, including Chester and Runcorn, and also Liverpool and Hawarden airports from -\n",
    "\n",
    "https://www.openstreetmap.org/export#map=12/53.2524/-2.8012\n",
    "![alt text](LargeMap.png \"Ellesmere Port\")\n",
    "\n",
    "Due to the large area, I had to download this using the \"Overpass API Query Form\" -\n",
    "http://overpass-api.de/query_form.html\n",
    "\n",
    "I used the following command -\n",
    "(node(**bottom,left,top,right**);<;);out meta;\n",
    "\n",
    "With the map parameters from the open street map, which in my case was -\n",
    "\n",
    "**(node(53.1626,-2.9890,53.3419,-2.6134);<;);out meta;**\n",
    "\n",
    "This gave me a large map file.\n",
    "\n",
    "**LargeMap.osm -> 175MB**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "## Cleaning The Data\n",
    "\n",
    "I then set about cleaning the data in this Jupyter notebook, first loading the required libraries -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "from collections import defaultdict\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I parsed the file, counting all of te types of tags (first on the small map, before the large map) -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<type 'int'>, {'node': 762937, 'member': 55116, 'nd': 1116253, 'tag': 367088, 'note': 1, 'meta': 1, 'relation': 2583, 'way': 146821, 'osm': 1})\n"
     ]
    }
   ],
   "source": [
    "def count_tags(filename):\n",
    "    counts = defaultdict(int)\n",
    "    for event, node in ET.iterparse(filename):\n",
    "        if event == 'end': \n",
    "            counts[node.tag]+=1\n",
    "        node.clear()             \n",
    "    return counts\n",
    "\n",
    "tags = count_tags('LargeMap.osm')      #('SmallMap.osm')\n",
    "pprint.pprint(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then used regular expressions to check for patterns and possible character problems in the data (again first on the small map, before then the large map) -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 240880, 'lower_colon': 111160, 'other': 15048, 'problemchars': 0}\n",
      "367088\n"
     ]
    }
   ],
   "source": [
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        if lower.search(element.attrib['k']):\n",
    "            keys['lower'] = keys['lower'] + 1\n",
    "        elif lower_colon.search(element.attrib['k']):\n",
    "            keys['lower_colon'] = keys['lower_colon'] + 1\n",
    "        elif problemchars.search(element.attrib['k']):\n",
    "            keys['problemchars'] = keys['problemchars'] + 1\n",
    "        else:\n",
    "            keys['other'] = keys['other'] + 1\n",
    "        pass        \n",
    "    return keys\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "    return keys\n",
    "\n",
    "keys = process_map('LargeMap.osm')      #('SmallMap.osm')\n",
    "pprint.pprint(keys)\n",
    "total = keys['lower'] + keys['lower_colon'] + keys['other']\n",
    "print total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then parsed the file cheking for any errors in the street names (again first on the small map, before then the large map) -\n",
    "\n",
    "The expected dictionary was created from all street types listed with more than street listed.\n",
    "I only found 5 errors, which I corrected with 4 entries in mapping.\n",
    "Only the 'St' set is shown for clarity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['Lower Bridge Street', 'Phillip Street'])\n"
     ]
    }
   ],
   "source": [
    "OSMFILE = \"LargeMap.osm\"      #('SmallMap.osm')\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "expected = [\"Arcades\", \"Avenue\", \"Bank\", \"Brow\", \"Close\", \"Cottages\", \"Court\", \"Crescent\", \"Croft\", \"Drive\",\n",
    "            \"East\", \"End\", \"Farm\", \"Fold\", \"Gardens\", \"Grange\", \"Green\", \"Grove\", \"Heath\", \"Hey\", \"Heys\", \"Hill\", \"Hollow\",\n",
    "            \"Meadows\", \"Mews\", \"North\", \"Lane\", \"Park\", \"Place\", \"Rise\", \"Road\", \"Row\", \"South\", \"Street\", \"Square\",\n",
    "            \"Terrace\", \"View\", \"Village\", \"Walk\", \"Way\", \"West\", \"Wharf\"]\n",
    "# Street types with more than one listing added to this list after initially running this cell\n",
    "\n",
    "mapping = { \"Rd\": \"Road\",\n",
    "            \"St\": \"Street\",\n",
    "            \"green\": \"Green\",\n",
    "            \"lane\": \"Lane\" }\n",
    "# Problems found - 'Liverpool Rd', 'Lower Bridge St', 'Phillip St', 'Mondrem green', 'Irons lane'\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(update_name(street_name, mapping))\n",
    "\n",
    "def update_name(name, mapping):\n",
    "    m = street_type_re.search(name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type in mapping:\n",
    "            name = re.sub(street_type_re, mapping[street_type], name)\n",
    "    return name\n",
    "\n",
    "st_types = audit(OSMFILE)\n",
    "pprint.pprint(dict(st_types)['St'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='csv'></a>\n",
    "## Create CSV Files\n",
    "I then edited my earlier used **data.py** file in Spyder, to outut the map as csv files, converting using the **schema.py** file from the previous lesson.\n",
    "\n",
    "Note that the CSV header lines are commented out, as when testing with the smaller area, I had import errors caused by the headers.\n",
    "\n",
    "This output my 5 csv files -\n",
    "\n",
    "**nodes.csv -----------> 60.7MB**\n",
    "\n",
    "**nodes_tags.csv ---> 1.52MB**\n",
    "\n",
    "**ways.csv ------------> 8.40MB**\n",
    "\n",
    "**ways_nodes.csv -> 26.5MB**\n",
    "\n",
    "**ways_tags.csv ----> 10.5MB**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sqldb'></a>\n",
    "## Create The SQL Database\n",
    "I then created a .bat (windows batch) file called **SQL.bat**, to create the database with sqlite3.\n",
    "\n",
    "Bat file command -\n",
    "\n",
    "**sqlite3.exe EllesmerePort.db \".read CreateDB.sql\"**\n",
    "\n",
    "This called up a modified version of the supplied schema -https://gist.github.com/swwelch/f1144229848b407e0a5d13fcb7fbbd6f\n",
    "which I had renamed **CreateDB.sql**\n",
    "\n",
    "I then ran the batch file, which output my database file -\n",
    "\n",
    "**EllesmerePort.db -> 96.4MB**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='queries'></a>\n",
    "## SQL Queries\n",
    "First I queried how many nodes and ways were present, which gave the same results as per the python 'count_tags' function earlier -"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sqlite> SELECT COUNT (*) from nodes;\n",
    "762937\n",
    "sqlite> SELECT COUNT (*) from ways;\n",
    "146821"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then counted how many unique users were present -"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sqlite> SELECT COUNT (DISTINCT(users.uid)) FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) users;\n",
    "595"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And output the top 10 contributing users -"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sqlite> SELECT users.user, COUNT (*) as num FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) users GROUP BY users.user ORDER BY num DESC LIMIT 10;\n",
    "daviesp12|479415\n",
    "Nathan2006|86575\n",
    "kjnpbr|85129\n",
    "Dyserth|44091\n",
    "smb1001|27092\n",
    "Chris Morley|19145\n",
    "mikh43|16637\n",
    "Colin Smale|11479\n",
    "pairmapper|10375\n",
    "RobChafer|9701"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='queries2'></a>\n",
    "## Further SQL Queries\n",
    "\n",
    "Then I counted which were the most popular amenities -"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sqlite> SELECT value, COUNT (*) as num FROM nodes_tags WHERE key=\"amenity\" GROUP BY value ORDER BY num DESC LIMIT 10;\n",
    "post_box|183\n",
    "pub|116\n",
    "bench|91\n",
    "restaurant|72\n",
    "telephone|71\n",
    "fast_food|63\n",
    "parking|55\n",
    "cafe|47\n",
    "post_office|31\n",
    "fuel|30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I live next to a large shopping outlet, I wanted to see which were the most common types of shops -"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sqlite> SELECT value, COUNT (*) as num FROM nodes_tags WHERE key=\"shop\" GROUP BY value ORDER BY num DESC LIMIT 10;\n",
    "clothes|92\n",
    "convenience|30\n",
    "yes|28\n",
    "hairdresser|27\n",
    "supermarket|14\n",
    "car_repair|12\n",
    "shoes|12\n",
    "car|11\n",
    "alcohol|7\n",
    "doityourself|7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the shopping outlet mainly being for designer clothes, this result was no suprise.\n",
    "\n",
    "I then decided to look at which were the most popular food offerings, looking at restaurants, fast food and cafes together -"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sqlite> SELECT nodes_tags.value, COUNT (*) as num FROM nodes_tags JOIN (SELECT DISTINCT(id) FROM nodes_tags\n",
    "   ...> WHERE value=\"cafe\" OR  value=\"fast_food\" OR  value=\"restaurant\")\n",
    "   ...> food ON nodes_tags.id=food.id WHERE nodes_tags.key=\"cuisine\" GROUP BY nodes_tags.value ORDER BY num DESC LIMIT 10;\n",
    "chinese|14\n",
    "indian|14\n",
    "coffee_shop|11\n",
    "fish_and_chips|11\n",
    "pizza|8\n",
    "sandwich|7\n",
    "italian|6\n",
    "international|4\n",
    "chicken|3\n",
    "regional|3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusions'></a>\n",
    "## Conclusions\n",
    "\n",
    "I noticed that some areas of OpenStreetMap are out of date, such as the EPSV Sports Centre a the entrance to my housing estate, which is still shown as Cheshire Oaks High School.\n",
    "In order to update areas such as this, first someone needs to identify that the data is out of date, before someone can upload the new building data, before verifying that the information is correct.\n",
    "\n",
    "Verifying OpenStreetMap data would be an ideal candidate for a more local based captcha system. Users could be shown only details from their current position, or from a wider area when then are based at home.\n",
    "Whilst having data checked more often would improve it's accuracy, users may not wish to see their location logged in such detail.\n",
    "Users would want to see the data managed by a trusted firm, with data use transparency being of the utmost importance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
